{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "951ef47f-1ee2-41c0-8568-a40f7bd43df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TASK_ID = 500\n",
    "TASK_NAME = \"Task500_Epaule\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25928c8a-33c5-4322-acae-393dd735b21e",
   "metadata": {},
   "source": [
    "With nnUNet, models are trained with 5-fold cross-validation. \n",
    "The postprocessing is determined after each fold training and the final postprecessing is determined by gathering each fold posprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199e169c-b9ea-4ea6-b6d3-769f678547db",
   "metadata": {},
   "source": [
    "# To train one fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68c05ac2-d90e-47cf-8958-aacddb67b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"2d\" # MODIFY HERE IF NEEDED\n",
    "fold = 0 # MODIFY HERE IF NEEDED\n",
    "\n",
    "if model == \"3d_cascade_fullres\":\n",
    "    trainer = \"nnUNetTrainerV2CascadeFullRes\"\n",
    "elif model.startswith(\"TransUNet\"):\n",
    "    trainer = \"TransUNetTrainer\"\n",
    "else:\n",
    "    trainer = \"nnUNetTrainerV2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd984a52-56e4-4626-9fee-d19474d68e81",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "TransUNet implementation from https://github.com/Beckschen/TransUNet\n",
      "###############################################\n",
      "I am running the following nnUNet: 2d\n",
      "My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\n",
      "For that I will be using the following configuration:\n",
      "num_classes:  5\n",
      "modalities:  {0: 'MRI_Dixon'}\n",
      "use_mask_for_norm OrderedDict([(0, False)])\n",
      "keep_only_largest_region None\n",
      "min_region_size_per_class None\n",
      "min_size_per_class None\n",
      "normalization_schemes OrderedDict([(0, 'nonCT')])\n",
      "stages...\n",
      "\n",
      "stage:  0\n",
      "{'batch_size': 44, 'num_pool_per_axis': [5, 6], 'patch_size': array([192, 384]), 'median_patient_size_in_voxels': array([384, 180, 384]), 'current_spacing': array([0.6875    , 0.66666669, 0.6875    ]), 'original_spacing': array([0.6875    , 0.66666669, 0.6875    ]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [1, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}\n",
      "\n",
      "I am using stage 0 from these plans\n",
      "I am using batch dice + CE loss\n",
      "\n",
      "I am using data from this folder:  /local/nnguye02/dataset/nnUNet_preprocessed/Task500_Epaule/nnUNetData_plans_v2.1_2D\n",
      "###############################################\n",
      "loading dataset\n",
      "loading all case properties\n",
      "2022-01-12 12:00:14.685632: Using splits from existing split file: /local/nnguye02/dataset/nnUNet_preprocessed/Task500_Epaule/splits_final.pkl\n",
      "2022-01-12 12:00:14.686043: The split file contains 5 splits.\n",
      "2022-01-12 12:00:14.686090: Desired fold for training: 0\n",
      "2022-01-12 12:00:14.686124: This split has 13 training and 4 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "2022-01-12 12:00:18.318949: lr: 0.01\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "2022-01-12 12:00:23.606692: \n",
      "epoch:  0\n",
      "2022-01-12 12:01:34.297973: train loss : 0.2826\n",
      "2022-01-12 12:01:40.102343: validation loss: 0.1144\n",
      "2022-01-12 12:01:40.103168: Average global foreground Dice: [0.0, 0.0, 0.0, 0.0, 0.2024]\n",
      "2022-01-12 12:01:40.103291: (interpret this as an estimate for the Dice of the different classes. This is not exact.)\n",
      "2022-01-12 12:01:40.528684: lr: 0.009991\n",
      "2022-01-12 12:01:40.528866: val critetion MA: 0.040472\n",
      "2022-01-12 12:01:40.528937: This epoch took 76.921774 s\n",
      "\n",
      "2022-01-12 12:01:40.528975: \n",
      "epoch:  1\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nnguye02/.local/bin/nnUNet_train\", line 33, in <module>\n",
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/projects/INSA-Image/Lib/conda/anaconda3/envs/pytorch1.9-cuda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "    sys.exit(load_entry_point('nnunet', 'console_scripts', 'nnUNet_train')())\n",
      "  File \"/projects/INSA-Image/Lib/conda/anaconda3/envs/pytorch1.9-cuda/lib/python3.8/threading.py\", line 870, in run\n",
      "  File \"/home/nnguye02/TDSI21-Shoulder-Muscle-Segmentation/nnunet/run/run_training.py\", line 183, in main\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/nnguye02/.local/lib/python3.8/site-packages/batchgenerators/dataloading/multi_threaded_augmenter.py\", line 102, in results_loop\n",
      "    trainer.run_training()\n",
      "  File \"/home/nnguye02/TDSI21-Shoulder-Muscle-Segmentation/nnunet/training/network_training/nnUNetTrainerV2.py\", line 441, in run_training\n",
      "    item = current_queue.get()\n",
      "  File \"/projects/INSA-Image/Lib/conda/anaconda3/envs/pytorch1.9-cuda/lib/python3.8/multiprocessing/queues.py\", line 116, in get\n",
      "    ret = super().run_training()\n",
      "  File \"/home/nnguye02/TDSI21-Shoulder-Muscle-Segmentation/nnunet/training/network_training/nnUNetTrainer.py\", line 317, in run_training\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/nnguye02/.local/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 289, in rebuild_storage_fd\n",
      "    super(nnUNetTrainer, self).run_training()\n",
      "  File \"/home/nnguye02/TDSI21-Shoulder-Muscle-Segmentation/nnunet/training/network_training/network_trainer.py\", line 460, in run_training\n",
      "    l = self.run_iteration(self.tr_gen, True)\n",
      "  File \"/home/nnguye02/TDSI21-Shoulder-Muscle-Segmentation/nnunet/training/network_training/nnUNetTrainerV2.py\", line 250, in run_iteration\n",
      "    fd = df.detach()\n",
      "    l = self.loss(output, target)\n",
      "  File \"/home/nnguye02/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "  File \"/projects/INSA-Image/Lib/conda/anaconda3/envs/pytorch1.9-cuda/lib/python3.8/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/projects/INSA-Image/Lib/conda/anaconda3/envs/pytorch1.9-cuda/lib/python3.8/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/projects/INSA-Image/Lib/conda/anaconda3/envs/pytorch1.9-cuda/lib/python3.8/multiprocessing/connection.py\", line 502, in Client\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/nnguye02/TDSI21-Shoulder-Muscle-Segmentation/nnunet/training/loss_functions/deep_supervision.py\", line 39, in forward\n",
      "    c = SocketClient(address)\n",
      "  File \"/projects/INSA-Image/Lib/conda/anaconda3/envs/pytorch1.9-cuda/lib/python3.8/multiprocessing/connection.py\", line 630, in SocketClient\n",
      "    l = weights[0] * self.loss(x[0], y[0])\n",
      "  File \"/home/nnguye02/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/nnguye02/TDSI21-Shoulder-Muscle-Segmentation/nnunet/training/loss_functions/dice_loss.py\", line 348, in forward\n",
      "    dc_loss = self.dc(net_output, target, loss_mask=mask) if self.weight_dice != 0 else 0\n",
      "  File \"/home/nnguye02/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/nnguye02/TDSI21-Shoulder-Muscle-Segmentation/nnunet/training/loss_functions/dice_loss.py\", line 180, in forward\n",
      "    tp, fp, fn, _ = get_tp_fp_fn_tn(x, y, axes, loss_mask, False)\n",
      "  File \"/home/nnguye02/TDSI21-Shoulder-Muscle-Segmentation/nnunet/training/loss_functions/dice_loss.py\", line 129, in get_tp_fp_fn_tn\n",
      "    y_onehot = y_onehot.cuda(net_output.device.index)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_train {model} {trainer} {TASK_NAME} {fold} --npz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbeac16-f294-4df2-bf15-5b187649feaf",
   "metadata": {},
   "source": [
    "# Get the final postprecessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3115b437-e46c-40fc-b910-6c981f22abe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "\n",
      "I will now ensemble combinations of the following models:\n",
      " ['2d']\n",
      "2d 0.8634831073369049\n",
      "Task500_Epaule submit model 2d 0.8634831073369049\n",
      "\n",
      "Here is how you should predict test cases. Run in sequential order and replace all input and output folder names with your personalized ones\n",
      "\n",
      "nnUNet_predict -i FOLDER_WITH_TEST_CASES -o OUTPUT_FOLDER_MODEL1 -tr nnUNetTrainerV2 -ctr nnUNetTrainerV2CascadeFullRes -m 2d -p nnUNetPlansv2.1 -t Task500_Epaule\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_find_best_configuration -m {model} -t {TASK_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e44f93-93d0-47fe-8e3c-be690fee550d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1.9-cuda",
   "language": "python",
   "name": "pytorch1.9-cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
